//! Reflection Agent - Self-Critique for Quality Improvement
//!
//! The **Reflection** pattern uses self-critique to iteratively improve output quality.
//! A generator creates responses, a critic evaluates them, and refinement continues
//! until quality thresholds are met.
//!
//! # Overview
//!
//! Reflection agents alternate between generation and critique:
//!
//! 1. **Generate**: Create initial response
//! 2. **Reflect**: Critic evaluates quality (0.0-1.0 score)
//! 3. **Refine**: Generator improves based on critique
//! 4. **Repeat**: Continue until quality threshold met or max iterations
//!
//! **Use Reflection when:**
//! - Output quality matters more than speed
//! - Writing, creative work, or complex reasoning tasks
//! - Need iterative improvement (essays, code, designs)
//! - Want explicit quality metrics
//!
//! **Don't use when:**
//! - Speed is critical (high token usage)
//! - Simple factual queries (use ReAct)
//! - First draft is usually sufficient
//!
//! # Architecture
//!
//! ```text
//! â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//! â”‚  User Input                                                 â”‚
//! â”‚  "Write a technical blog post about Rust ownership"        â”‚
//! â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//!               â”‚
//!               â†“ START
//! â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//! â”‚  Generator Node (Create Response)                           â”‚
//! â”‚  â€¢ Writes initial draft                                     â”‚
//! â”‚  â€¢ Returns response text                                    â”‚
//! â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//!               â”‚
//!               â†“ Iteration 1
//! â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//! â”‚  Reflector Node (Critique Quality)                          â”‚
//! â”‚  Evaluates draft:                                           â”‚
//! â”‚  â€¢ Quality score: 0.6                                       â”‚
//! â”‚  â€¢ Weaknesses: "Lacks examples, unclear structure"          â”‚
//! â”‚  â€¢ Suggestions: "Add code examples, reorganize sections"    â”‚
//! â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//!               â”‚
//!               â†“ Score < 0.8 (threshold)
//! â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//! â”‚  Generator Node (Refine)                                    â”‚
//! â”‚  â€¢ Sees critique                                            â”‚
//! â”‚  â€¢ Adds examples, improves structure                        â”‚
//! â”‚  â€¢ Returns improved version                                 â”‚
//! â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//!               â”‚
//!               â†“ Iteration 2
//! â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//! â”‚  Reflector Node (Re-evaluate)                               â”‚
//! â”‚  â€¢ Quality score: 0.85                                      â”‚
//! â”‚  â€¢ Meets threshold â†’ END                                    â”‚
//! â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//! ```
//!
//! # Quick Start
//!
//! ```rust,ignore
//! use langgraph_prebuilt::create_reflection_agent;
//! use std::sync::Arc;
//!
//! // Generator: creates and refines content
//! let generator_llm = Arc::new(|state| {
//!     Box::pin(async move {
//!         let content = generate_content(state).await?;
//!         Ok(Message::ai(content))
//!     }) as Pin<Box<dyn Future<Output = _> + Send>>
//! });
//!
//! // Reflector: critiques quality
//! let reflector_llm = Arc::new(|state| {
//!     Box::pin(async move {
//!         let critique = evaluate_quality(state).await?;
//!         Ok(Message::ai(critique))
//!     }) as Pin<Box<dyn Future<Output = _> + Send>>
//! });
//!
//! // Create agent
//! let agent = create_reflection_agent(generator_llm, reflector_llm)
//!     .with_max_iterations(3)
//!     .with_quality_threshold(0.8)
//!     .build()?;
//!
//! // Generate high-quality output
//! let result = agent.invoke(json!({
//!     "query": "Explain Rust borrowing to beginners"
//! })).await?;
//! ```
//!
//! # Common Patterns
//!
//! ## Pattern 1: Technical Writing
//!
//! ```rust,ignore
//! let writer = create_reflection_agent(generator, critic)
//!     .with_max_iterations(5)
//!     .with_quality_threshold(0.85)
//!     .with_generator_prompt(
//!         "You are a technical writer. Write clear, accurate documentation."
//!     )
//!     .with_reflector_prompt(
//!         "Evaluate technical accuracy, clarity, and completeness. \
//!          Score 0-1 based on: correctness, examples, structure."
//!     )
//!     .build()?;
//!
//! let doc = writer.invoke(json!({
//!     "query": "Document the async/await feature in Rust"
//! })).await?;
//! ```
//!
//! ## Pattern 2: Code Generation with Review
//!
//! ```rust,ignore
//! let code_agent = create_reflection_agent(coder, reviewer)
//!     .with_max_iterations(4)
//!     .with_quality_threshold(0.9) // High bar for code
//!     .build()?;
//!
//! let code = code_agent.invoke(json!({
//!     "query": "Write a thread-safe LRU cache in Rust"
//! })).await?;
//! ```
//!
//! # Key Components
//!
//! ## ReflectionCritique
//!
//! ```rust,ignore
//! pub struct ReflectionCritique {
//!     quality_score: f64,           // 0.0-1.0
//!     strengths: Vec<String>,       // What works well
//!     weaknesses: Vec<String>,      // What needs work
//!     suggestions: Vec<String>,     // How to improve
//!     is_satisfactory: bool,        // Meets threshold?
//! }
//! ```
//!
//! ## ReflectionState
//!
//! ```rust,ignore
//! pub struct ReflectionState {
//!     query: String,                // Original request
//!     current_response: String,     // Latest version
//!     response_history: Vec<String>,// All versions
//!     critique_history: Vec<ReflectionCritique>,
//!     iteration_count: usize,
//!     final_response: Option<String>,
//!     quality_metrics: Option<QualityMetrics>,
//! }
//! ```
//!
//! # Configuration
//!
//! | Method | Description | Default |
//! |--------|-------------|---------|
//! | `with_max_iterations(n)` | Max refinement cycles | 3 |
//! | `with_quality_threshold(f)` | Min quality score (0-1) | 0.8 |
//! | `with_generator_prompt(s)` | Generator instructions | None |
//! | `with_reflector_prompt(s)` | Critic instructions | None |
//!
//! ## Quality Thresholds
//!
//! ```rust,ignore
//! // Relaxed (faster, less refined)
//! .with_quality_threshold(0.7)
//!
//! // Balanced (default)
//! .with_quality_threshold(0.8)
//!
//! // Strict (slower, higher quality)
//! .with_quality_threshold(0.9)
//! ```
//!
//! # Performance Considerations
//!
//! - **Token usage**: 3-10x more than ReAct (multiple LLM calls per iteration)
//! - **Latency**: 10-30 seconds typical (3 iterations)
//! - **Quality gain**: +20-40% improvement over single-shot
//!
//! **Cost-performance tradeoffs:**
//! - Max iterations: 2-3 for blog posts, 4-5 for critical content
//! - Quality threshold: 0.7-0.8 for speed, 0.85-0.95 for quality
//!
//! # Python LangGraph Comparison
//!
//! | Python | Rust |
//! |--------|------|
//! | `create_reflection_agent(...)` | `create_reflection_agent(...).build()` |
//! | Single LLM for both roles | Separate generator and reflector |
//!
//! # See Also
//!
//! - [`create_reflection_agent`] - Factory function
//! - [`ReflectionCritique`] - Critique structure
//! - [`ReflectionState`] - Agent state
//! - [`QualityMetrics`] - Quality tracking
//! - [`create_react_agent`](super::react::create_react_agent) - Faster alternative
//! - [`create_plan_execute_agent`](super::plan_execute::create_plan_execute_agent) - Planning-focused alternative

use crate::error::{PrebuiltError, Result};
use crate::messages::Message;
use crate::tools::Tool;
use langgraph_core::StateGraph;
use langgraph_core::compiled::CompiledGraph;
use serde::{Deserialize, Serialize};
use serde_json::{json, Value};
use std::sync::Arc;

/// Type alias for LLM functions
pub type LlmFunction = Arc<dyn Fn(Value) -> std::pin::Pin<Box<dyn std::future::Future<Output = Result<Message>> + Send>> + Send + Sync>;

/// Represents a single reflection critique
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReflectionCritique {
    /// Overall quality score (0.0 to 1.0)
    pub quality_score: f64,

    /// Areas where the response excels
    pub strengths: Vec<String>,

    /// Areas needing improvement
    pub weaknesses: Vec<String>,

    /// Specific suggestions for improvement
    pub suggestions: Vec<String>,

    /// Whether the response meets quality thresholds
    pub is_satisfactory: bool,
}

/// State for the Reflection agent
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReflectionState {
    /// Original user query
    pub query: String,

    /// Current response being refined
    pub current_response: String,

    /// History of all generated responses
    pub response_history: Vec<String>,

    /// History of all reflection critiques
    pub critique_history: Vec<ReflectionCritique>,

    /// Number of reflection iterations completed
    pub iteration_count: usize,

    /// Final refined response
    #[serde(skip_serializing_if = "Option::is_none")]
    pub final_response: Option<String>,

    /// Overall quality metrics
    #[serde(skip_serializing_if = "Option::is_none")]
    pub quality_metrics: Option<QualityMetrics>,
}

/// Quality metrics for the final response
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QualityMetrics {
    /// Final quality score
    pub final_score: f64,

    /// Number of iterations taken
    pub iterations: usize,

    /// Total improvement from first to final
    pub improvement_delta: f64,

    /// Whether quality threshold was met
    pub threshold_met: bool,
}

/// Configuration for Reflection agent
pub struct ReflectionConfig {
    /// LLM function for generating responses
    generator_llm: LlmFunction,

    /// LLM function for reflecting/critiquing
    reflector_llm: LlmFunction,

    /// Tools available to the agent (optional)
    tools: Vec<Box<dyn Tool>>,

    /// Maximum number of reflection iterations
    max_iterations: usize,

    /// Minimum quality score threshold (0.0 to 1.0)
    quality_threshold: f64,

    /// System prompt for the generator
    generator_prompt: Option<String>,

    /// System prompt for the reflector
    reflector_prompt: Option<String>,

    /// Whether to use tools during generation
    use_tools: bool,
}

impl ReflectionConfig {
    /// Create a new Reflection configuration
    pub fn new(
        generator_llm: LlmFunction,
        reflector_llm: LlmFunction,
        tools: Vec<Box<dyn Tool>>,
    ) -> Self {
        Self {
            generator_llm,
            reflector_llm,
            tools,
            max_iterations: 3,
            quality_threshold: 0.75,
            generator_prompt: None,
            reflector_prompt: None,
            use_tools: true,
        }
    }

    /// Set maximum reflection iterations
    pub fn with_max_iterations(mut self, max: usize) -> Self {
        self.max_iterations = max;
        self
    }

    /// Set quality threshold (0.0 to 1.0)
    pub fn with_quality_threshold(mut self, threshold: f64) -> Self {
        self.quality_threshold = threshold.clamp(0.0, 1.0);
        self
    }

    /// Set generator system prompt
    pub fn with_generator_prompt(mut self, prompt: impl Into<String>) -> Self {
        self.generator_prompt = Some(prompt.into());
        self
    }

    /// Set reflector system prompt
    pub fn with_reflector_prompt(mut self, prompt: impl Into<String>) -> Self {
        self.reflector_prompt = Some(prompt.into());
        self
    }

    /// Set whether to use tools during generation
    pub fn with_use_tools(mut self, use_tools: bool) -> Self {
        self.use_tools = use_tools;
        self
    }

    /// Build the compiled Reflection agent graph
    pub fn build(self) -> Result<CompiledGraph> {
        build_reflection_graph(self)
    }
}

/// Build the Reflection agent graph
fn build_reflection_graph(config: ReflectionConfig) -> Result<CompiledGraph> {
    let mut graph = StateGraph::new();

    let generator_llm = config.generator_llm.clone();
    let reflector_llm = config.reflector_llm.clone();
    let tools = Arc::new(config.tools);
    let max_iterations = config.max_iterations;
    let quality_threshold = config.quality_threshold;
    let use_tools = config.use_tools;

    // Generator node - generates or improves responses
    let tools_for_generator = tools.clone();
    graph.add_node("generator", move |state: Value| {
        let generator = generator_llm.clone();
        let tools = tools_for_generator.clone();
        let use_tools_copy = use_tools;

        Box::pin(async move {
            let mut state_obj = state.as_object().cloned().unwrap_or_default();

            // Get query and iteration info
            let query = state_obj.get("query")
                .and_then(|v| v.as_str())
                .unwrap_or("")
                .to_string();

            let iteration_count = state_obj.get("iteration_count")
                .and_then(|v| v.as_u64())
                .unwrap_or(0) as usize;

            let critique_history = state_obj.get("critique_history")
                .and_then(|v| serde_json::from_value::<Vec<ReflectionCritique>>(v.clone()).ok())
                .unwrap_or_default();

            // Create generation prompt
            let prompt = if iteration_count == 0 {
                format!("Please provide a comprehensive response to: {}", query)
            } else {
                let last_critique = critique_history.last();
                let mut prompt = format!(
                    "Please improve your response to: {}\n\n",
                    query
                );

                if let Some(critique) = last_critique {
                    prompt.push_str("Based on the following feedback:\n");
                    prompt.push_str(&format!("Weaknesses: {}\n", critique.weaknesses.join(", ")));
                    prompt.push_str(&format!("Suggestions: {}\n", critique.suggestions.join(", ")));
                    prompt.push_str("\nProvide an improved response addressing these issues.");
                }

                prompt
            };

            // Call generator LLM
            let generator_input = json!({
                "messages": [{"role": "user", "content": prompt}],
                "use_tools": use_tools_copy
            });

            let response = generator(generator_input).await
                .map_err(|e| langgraph_core::GraphError::Execution(e.to_string()))?;

            // Update response history
            let mut response_history = state_obj.get("response_history")
                .and_then(|v| v.as_array())
                .cloned()
                .unwrap_or_default();

            let new_response = response.content.clone();
            response_history.push(json!(new_response));

            // Update state
            state_obj.insert("current_response".to_string(), json!(new_response));
            state_obj.insert("response_history".to_string(), Value::Array(response_history));
            state_obj.insert("iteration_count".to_string(), json!(iteration_count));

            Ok(Value::Object(state_obj))
        })
    });

    // Reflector node - critiques the current response
    graph.add_node("reflector", move |state: Value| {
        let reflector = reflector_llm.clone();
        let quality_threshold_copy = quality_threshold;

        Box::pin(async move {
            let mut state_obj = state.as_object().cloned().unwrap_or_default();

            let query = state_obj.get("query")
                .and_then(|v| v.as_str())
                .unwrap_or("")
                .to_string();

            let current_response = state_obj.get("current_response")
                .and_then(|v| v.as_str())
                .unwrap_or("")
                .to_string();

            let iteration_count = state_obj.get("iteration_count")
                .and_then(|v| v.as_u64())
                .unwrap_or(0) as usize;

            // Create reflection prompt
            let reflection_prompt = format!(
                "Critically evaluate this response to the query:\n\nQuery: {}\n\nResponse: {}\n\n\
                 Provide a JSON critique with:\n\
                 - quality_score (0.0 to 1.0)\n\
                 - strengths (array of strings)\n\
                 - weaknesses (array of strings)\n\
                 - suggestions (array of specific improvements)\n\
                 - is_satisfactory (boolean, true if score >= {})",
                query, current_response, quality_threshold_copy
            );

            let reflector_input = json!({
                "messages": [{"role": "user", "content": reflection_prompt}]
            });

            // Call reflector LLM
            let reflection = reflector(reflector_input).await
                .map_err(|e| langgraph_core::GraphError::Execution(e.to_string()))?;

            // Parse critique from response (simplified - in production, use proper JSON extraction)
            let critique = parse_critique_from_response(&reflection, quality_threshold_copy);

            // Update critique history
            let mut critique_history = state_obj.get("critique_history")
                .and_then(|v| serde_json::from_value::<Vec<ReflectionCritique>>(v.clone()).ok())
                .unwrap_or_default();

            critique_history.push(critique.clone());

            // Update state
            state_obj.insert("critique_history".to_string(),
                serde_json::to_value(&critique_history).map_err(|e| langgraph_core::GraphError::Serialization(e))?);
            state_obj.insert("iteration_count".to_string(), json!(iteration_count + 1));

            // Check if we should finalize
            if critique.is_satisfactory || iteration_count + 1 >= max_iterations {
                // Calculate final metrics
                let first_score = critique_history.first()
                    .map(|c| c.quality_score)
                    .unwrap_or(0.0);

                let metrics = QualityMetrics {
                    final_score: critique.quality_score,
                    iterations: iteration_count + 1,
                    improvement_delta: critique.quality_score - first_score,
                    threshold_met: critique.is_satisfactory,
                };

                state_obj.insert("final_response".to_string(), json!(current_response));
                state_obj.insert("quality_metrics".to_string(),
                    serde_json::to_value(&metrics).map_err(|e| langgraph_core::GraphError::Serialization(e))?);
            }

            Ok(Value::Object(state_obj))
        })
    });

    // Add edges
    graph.add_edge("__start__", "generator");
    graph.add_edge("generator", "reflector");

    // Conditional routing from reflector
    let max_iterations_for_routing = max_iterations;
    graph.add_conditional_edge(
        "reflector",
        move |state: &Value| {
            use langgraph_core::send::ConditionalEdgeResult;

            // Check if we have a final response (either satisfactory or max iterations reached)
            if state.get("final_response").is_some() {
                ConditionalEdgeResult::Node("__end__".to_string())
            } else {
                // Continue iterating
                ConditionalEdgeResult::Node("generator".to_string())
            }
        },
        vec![
            ("__end__".to_string(), "__end__".to_string()),
            ("generator".to_string(), "generator".to_string()),
        ].into_iter().collect(),
    );

    // Compile and return
    graph.compile().map_err(|e| PrebuiltError::Graph(e))
}

/// Helper function to parse critique from LLM response
fn parse_critique_from_response(response: &Message, quality_threshold: f64) -> ReflectionCritique {
    // Simplified parsing - in production, use proper JSON extraction from the LLM response
    // This would parse the structured critique from the LLM's JSON output

    // For now, create a mock critique
    let quality_score = 0.7; // Would be extracted from response

    ReflectionCritique {
        quality_score,
        strengths: vec!["Clear explanation".to_string()],
        weaknesses: vec!["Could be more detailed".to_string()],
        suggestions: vec!["Add more examples".to_string()],
        is_satisfactory: quality_score >= quality_threshold,
    }
}

/// Create a Reflection agent with the given configuration
pub fn create_reflection_agent(
    generator_llm: LlmFunction,
    reflector_llm: LlmFunction,
    tools: Vec<Box<dyn Tool>>,
) -> ReflectionConfig {
    ReflectionConfig::new(generator_llm, reflector_llm, tools)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_critique_serialization() {
        let critique = ReflectionCritique {
            quality_score: 0.85,
            strengths: vec!["Good structure".to_string()],
            weaknesses: vec!["Lacks examples".to_string()],
            suggestions: vec!["Add code samples".to_string()],
            is_satisfactory: true,
        };

        let serialized = serde_json::to_string(&critique).unwrap();
        let deserialized: ReflectionCritique = serde_json::from_str(&serialized).unwrap();

        assert_eq!(critique.quality_score, deserialized.quality_score);
        assert_eq!(critique.is_satisfactory, deserialized.is_satisfactory);
    }

    #[test]
    fn test_state_serialization() {
        let state = ReflectionState {
            query: "Test query".to_string(),
            current_response: "Test response".to_string(),
            response_history: vec![],
            critique_history: vec![],
            iteration_count: 0,
            final_response: None,
            quality_metrics: None,
        };

        let serialized = serde_json::to_string(&state).unwrap();
        let deserialized: ReflectionState = serde_json::from_str(&serialized).unwrap();

        assert_eq!(state.query, deserialized.query);
        assert_eq!(state.iteration_count, deserialized.iteration_count);
    }

    // ========== Config and Builder Tests ==========

    #[test]
    fn test_config_default_values() {
        let generator: LlmFunction = Arc::new(|_| Box::pin(async { Ok(Message::ai("generate")) }));
        let reflector: LlmFunction = Arc::new(|_| Box::pin(async { Ok(Message::ai("reflect")) }));

        let config = ReflectionConfig::new(generator, reflector, vec![]);

        assert_eq!(config.max_iterations, 3);
        assert_eq!(config.quality_threshold, 0.75);
        assert!(config.generator_prompt.is_none());
        assert!(config.reflector_prompt.is_none());
        assert!(config.use_tools);
    }

    #[test]
    fn test_config_builder_pattern() {
        let generator: LlmFunction = Arc::new(|_| Box::pin(async { Ok(Message::ai("generate")) }));
        let reflector: LlmFunction = Arc::new(|_| Box::pin(async { Ok(Message::ai("reflect")) }));

        let config = create_reflection_agent(generator, reflector, vec![])
            .with_max_iterations(5)
            .with_quality_threshold(0.9)
            .with_generator_prompt("Generate content")
            .with_reflector_prompt("Critique content")
            .with_use_tools(false);

        assert_eq!(config.max_iterations, 5);
        assert_eq!(config.quality_threshold, 0.9);
        assert_eq!(config.generator_prompt.unwrap(), "Generate content");
        assert_eq!(config.reflector_prompt.unwrap(), "Critique content");
        assert!(!config.use_tools);
    }

    #[test]
    fn test_config_with_max_iterations() {
        let generator: LlmFunction = Arc::new(|_| Box::pin(async { Ok(Message::ai("generate")) }));
        let reflector: LlmFunction = Arc::new(|_| Box::pin(async { Ok(Message::ai("reflect")) }));

        let config = ReflectionConfig::new(generator, reflector, vec![])
            .with_max_iterations(10);

        assert_eq!(config.max_iterations, 10);
        assert_eq!(config.quality_threshold, 0.75); // Default unchanged
    }

    #[test]
    fn test_config_quality_threshold_clamping() {
        let generator: LlmFunction = Arc::new(|_| Box::pin(async { Ok(Message::ai("generate")) }));
        let reflector: LlmFunction = Arc::new(|_| Box::pin(async { Ok(Message::ai("reflect")) }));

        let config_high = ReflectionConfig::new(generator.clone(), reflector.clone(), vec![])
            .with_quality_threshold(1.5); // Should clamp to 1.0

        assert_eq!(config_high.quality_threshold, 1.0);

        let config_low = ReflectionConfig::new(generator.clone(), reflector.clone(), vec![])
            .with_quality_threshold(-0.5); // Should clamp to 0.0

        assert_eq!(config_low.quality_threshold, 0.0);

        let config_valid = ReflectionConfig::new(generator, reflector, vec![])
            .with_quality_threshold(0.85);

        assert_eq!(config_valid.quality_threshold, 0.85);
    }

    #[test]
    fn test_config_chaining() {
        let generator: LlmFunction = Arc::new(|_| Box::pin(async { Ok(Message::ai("generate")) }));
        let reflector: LlmFunction = Arc::new(|_| Box::pin(async { Ok(Message::ai("reflect")) }));

        let config = ReflectionConfig::new(generator, reflector, vec![])
            .with_max_iterations(2)
            .with_quality_threshold(0.8)
            .with_generator_prompt("A")
            .with_reflector_prompt("B")
            .with_use_tools(true);

        assert_eq!(config.max_iterations, 2);
        assert_eq!(config.quality_threshold, 0.8);
        assert_eq!(config.generator_prompt.unwrap(), "A");
        assert_eq!(config.reflector_prompt.unwrap(), "B");
        assert!(config.use_tools);
    }

    #[test]
    fn test_config_zero_max_iterations() {
        let generator: LlmFunction = Arc::new(|_| Box::pin(async { Ok(Message::ai("generate")) }));
        let reflector: LlmFunction = Arc::new(|_| Box::pin(async { Ok(Message::ai("reflect")) }));

        let config = ReflectionConfig::new(generator, reflector, vec![])
            .with_max_iterations(0);

        assert_eq!(config.max_iterations, 0);
    }

    #[test]
    fn test_config_use_tools() {
        let generator: LlmFunction = Arc::new(|_| Box::pin(async { Ok(Message::ai("generate")) }));
        let reflector: LlmFunction = Arc::new(|_| Box::pin(async { Ok(Message::ai("reflect")) }));

        let config_with_tools = ReflectionConfig::new(generator.clone(), reflector.clone(), vec![])
            .with_use_tools(true);

        assert!(config_with_tools.use_tools);

        let config_without_tools = ReflectionConfig::new(generator, reflector, vec![])
            .with_use_tools(false);

        assert!(!config_without_tools.use_tools);
    }

    // ========== Quality Assessment Tests ==========

    #[test]
    fn test_parse_critique_default() {
        let response = Message::ai("This response needs improvement");
        let critique = parse_critique_from_response(&response, 0.75);

        assert_eq!(critique.quality_score, 0.7);
        assert!(!critique.is_satisfactory); // 0.7 < 0.75
        assert!(!critique.strengths.is_empty());
        assert!(!critique.weaknesses.is_empty());
        assert!(!critique.suggestions.is_empty());
    }

    #[test]
    fn test_critique_is_satisfactory_below_threshold() {
        let critique = ReflectionCritique {
            quality_score: 0.74,
            strengths: vec![],
            weaknesses: vec![],
            suggestions: vec![],
            is_satisfactory: false,
        };

        assert!(!critique.is_satisfactory);
        assert!(critique.quality_score < 0.75);
    }

    #[test]
    fn test_critique_is_satisfactory_at_threshold() {
        let critique = ReflectionCritique {
            quality_score: 0.75,
            strengths: vec![],
            weaknesses: vec![],
            suggestions: vec![],
            is_satisfactory: true,
        };

        assert!(critique.is_satisfactory);
        assert_eq!(critique.quality_score, 0.75);
    }

    #[test]
    fn test_critique_is_satisfactory_above_threshold() {
        let critique = ReflectionCritique {
            quality_score: 0.95,
            strengths: vec!["Excellent".to_string()],
            weaknesses: vec![],
            suggestions: vec![],
            is_satisfactory: true,
        };

        assert!(critique.is_satisfactory);
        assert!(critique.quality_score > 0.75);
    }

    #[test]
    fn test_quality_metrics_calculation() {
        let metrics = QualityMetrics {
            final_score: 0.9,
            iterations: 3,
            improvement_delta: 0.2, // 0.9 - 0.7
            threshold_met: true,
        };

        assert_eq!(metrics.final_score, 0.9);
        assert_eq!(metrics.iterations, 3);
        assert_eq!(metrics.improvement_delta, 0.2);
        assert!(metrics.threshold_met);
    }

    #[test]
    fn test_quality_metrics_no_improvement() {
        let metrics = QualityMetrics {
            final_score: 0.7,
            iterations: 1,
            improvement_delta: 0.0,
            threshold_met: false,
        };

        assert_eq!(metrics.improvement_delta, 0.0);
        assert!(!metrics.threshold_met);
    }

    #[test]
    fn test_quality_metrics_negative_delta() {
        // Edge case: quality got worse (shouldn't happen but test handles it)
        let metrics = QualityMetrics {
            final_score: 0.6,
            iterations: 2,
            improvement_delta: -0.1, // 0.6 - 0.7
            threshold_met: false,
        };

        assert_eq!(metrics.improvement_delta, -0.1);
        assert!(metrics.improvement_delta < 0.0);
    }

    #[test]
    fn test_critique_with_detailed_feedback() {
        let critique = ReflectionCritique {
            quality_score: 0.82,
            strengths: vec![
                "Clear structure".to_string(),
                "Good examples".to_string(),
            ],
            weaknesses: vec![
                "Missing conclusion".to_string(),
            ],
            suggestions: vec![
                "Add summary section".to_string(),
                "Include references".to_string(),
            ],
            is_satisfactory: true,
        };

        assert_eq!(critique.strengths.len(), 2);
        assert_eq!(critique.weaknesses.len(), 1);
        assert_eq!(critique.suggestions.len(), 2);
    }

    // ========== Generation-Critique Cycle Tests ==========

    #[test]
    fn test_state_initialization() {
        let state = ReflectionState {
            query: "Write an essay".to_string(),
            current_response: String::new(),
            response_history: vec![],
            critique_history: vec![],
            iteration_count: 0,
            final_response: None,
            quality_metrics: None,
        };

        assert_eq!(state.query, "Write an essay");
        assert_eq!(state.iteration_count, 0);
        assert!(state.response_history.is_empty());
        assert!(state.critique_history.is_empty());
        assert!(state.final_response.is_none());
        assert!(state.quality_metrics.is_none());
    }

    #[test]
    fn test_response_history_tracking() {
        let mut state = ReflectionState {
            query: "Test".to_string(),
            current_response: "Response 1".to_string(),
            response_history: vec!["Response 1".to_string()],
            critique_history: vec![],
            iteration_count: 1,
            final_response: None,
            quality_metrics: None,
        };

        assert_eq!(state.response_history.len(), 1);

        // Simulate next iteration
        state.current_response = "Response 2".to_string();
        state.response_history.push("Response 2".to_string());
        state.iteration_count = 2;

        assert_eq!(state.response_history.len(), 2);
        assert_eq!(state.iteration_count, 2);
        assert_eq!(state.current_response, "Response 2");
    }

    #[test]
    fn test_critique_history_tracking() {
        let critique1 = ReflectionCritique {
            quality_score: 0.6,
            strengths: vec![],
            weaknesses: vec!["Too brief".to_string()],
            suggestions: vec!["Expand".to_string()],
            is_satisfactory: false,
        };

        let critique2 = ReflectionCritique {
            quality_score: 0.85,
            strengths: vec!["Well detailed".to_string()],
            weaknesses: vec![],
            suggestions: vec![],
            is_satisfactory: true,
        };

        let state = ReflectionState {
            query: "Test".to_string(),
            current_response: "Final response".to_string(),
            response_history: vec!["Response 1".to_string(), "Response 2".to_string()],
            critique_history: vec![critique1, critique2],
            iteration_count: 2,
            final_response: None,
            quality_metrics: None,
        };

        assert_eq!(state.critique_history.len(), 2);
        assert_eq!(state.critique_history[0].quality_score, 0.6);
        assert_eq!(state.critique_history[1].quality_score, 0.85);
    }

    #[test]
    fn test_iteration_counting() {
        let mut state = ReflectionState {
            query: "Test".to_string(),
            current_response: String::new(),
            response_history: vec![],
            critique_history: vec![],
            iteration_count: 0,
            final_response: None,
            quality_metrics: None,
        };

        for i in 1..=5 {
            state.iteration_count = i;
            assert_eq!(state.iteration_count, i);
        }
    }

    #[test]
    fn test_final_response_setting() {
        let mut state = ReflectionState {
            query: "Test".to_string(),
            current_response: "Latest response".to_string(),
            response_history: vec![],
            critique_history: vec![],
            iteration_count: 3,
            final_response: None,
            quality_metrics: None,
        };

        assert!(state.final_response.is_none());

        state.final_response = Some(state.current_response.clone());

        assert!(state.final_response.is_some());
        assert_eq!(state.final_response.unwrap(), "Latest response");
    }

    #[test]
    fn test_complete_cycle() {
        let critique = ReflectionCritique {
            quality_score: 0.9,
            strengths: vec!["Comprehensive".to_string()],
            weaknesses: vec![],
            suggestions: vec![],
            is_satisfactory: true,
        };

        let metrics = QualityMetrics {
            final_score: 0.9,
            iterations: 2,
            improvement_delta: 0.25,
            threshold_met: true,
        };

        let state = ReflectionState {
            query: "Write guide".to_string(),
            current_response: "Final draft".to_string(),
            response_history: vec!["Draft 1".to_string(), "Final draft".to_string()],
            critique_history: vec![critique],
            iteration_count: 2,
            final_response: Some("Final draft".to_string()),
            quality_metrics: Some(metrics),
        };

        assert_eq!(state.iteration_count, 2);
        assert_eq!(state.response_history.len(), 2);
        assert_eq!(state.critique_history.len(), 1);
        assert!(state.final_response.is_some());
        assert!(state.quality_metrics.is_some());

        let metrics = state.quality_metrics.unwrap();
        assert!(metrics.threshold_met);
        assert_eq!(metrics.improvement_delta, 0.25);
    }

    // ========== Iteration Limits Tests ==========

    #[test]
    fn test_max_iterations_enforcement() {
        let state = json!({
            "iteration_count": 3,
            "final_response": "Result after max iterations"
        });

        // With max_iterations = 3, should have final_response
        assert!(state.get("final_response").is_some());
        assert_eq!(state["iteration_count"], 3);
    }

    #[test]
    fn test_early_termination_on_satisfactory() {
        let critique = ReflectionCritique {
            quality_score: 0.95,
            strengths: vec!["Excellent".to_string()],
            weaknesses: vec![],
            suggestions: vec![],
            is_satisfactory: true,
        };

        let state = ReflectionState {
            query: "Test".to_string(),
            current_response: "Great response".to_string(),
            response_history: vec!["Great response".to_string()],
            critique_history: vec![critique],
            iteration_count: 1, // Terminated early (before max)
            final_response: Some("Great response".to_string()),
            quality_metrics: Some(QualityMetrics {
                final_score: 0.95,
                iterations: 1,
                improvement_delta: 0.0,
                threshold_met: true,
            }),
        };

        assert_eq!(state.iteration_count, 1);
        assert!(state.final_response.is_some());
        assert!(state.quality_metrics.as_ref().unwrap().threshold_met);
    }

    #[test]
    fn test_threshold_met_tracking() {
        let metrics_met = QualityMetrics {
            final_score: 0.85,
            iterations: 2,
            improvement_delta: 0.15,
            threshold_met: true,
        };

        assert!(metrics_met.threshold_met);

        let metrics_not_met = QualityMetrics {
            final_score: 0.7,
            iterations: 3,
            improvement_delta: 0.1,
            threshold_met: false,
        };

        assert!(!metrics_not_met.threshold_met);
    }

    #[test]
    fn test_metrics_at_max_iterations() {
        // Even if quality not met, should have metrics at max iterations
        let metrics = QualityMetrics {
            final_score: 0.72,
            iterations: 5, // max_iterations reached
            improvement_delta: 0.12,
            threshold_met: false, // Didn't reach threshold
        };

        assert_eq!(metrics.iterations, 5);
        assert!(!metrics.threshold_met);
        assert!(metrics.improvement_delta > 0.0); // But did improve
    }

    #[test]
    fn test_one_iteration_limit() {
        let state = ReflectionState {
            query: "Test".to_string(),
            current_response: "Single response".to_string(),
            response_history: vec!["Single response".to_string()],
            critique_history: vec![ReflectionCritique {
                quality_score: 0.65,
                strengths: vec![],
                weaknesses: vec!["Needs work".to_string()],
                suggestions: vec![],
                is_satisfactory: false,
            }],
            iteration_count: 1,
            final_response: Some("Single response".to_string()),
            quality_metrics: Some(QualityMetrics {
                final_score: 0.65,
                iterations: 1,
                improvement_delta: 0.0,
                threshold_met: false,
            }),
        };

        assert_eq!(state.iteration_count, 1);
        assert!(state.final_response.is_some());
        assert!(!state.quality_metrics.unwrap().threshold_met);
    }

    #[test]
    fn test_multiple_iterations_progress() {
        let critiques = vec![
            ReflectionCritique {
                quality_score: 0.5,
                strengths: vec![],
                weaknesses: vec!["Poor".to_string()],
                suggestions: vec!["Improve".to_string()],
                is_satisfactory: false,
            },
            ReflectionCritique {
                quality_score: 0.7,
                strengths: vec!["Better".to_string()],
                weaknesses: vec!["Still needs work".to_string()],
                suggestions: vec!["Polish".to_string()],
                is_satisfactory: false,
            },
            ReflectionCritique {
                quality_score: 0.88,
                strengths: vec!["Excellent".to_string()],
                weaknesses: vec![],
                suggestions: vec![],
                is_satisfactory: true,
            },
        ];

        assert_eq!(critiques[0].quality_score, 0.5);
        assert_eq!(critiques[1].quality_score, 0.7);
        assert_eq!(critiques[2].quality_score, 0.88);
        assert!(critiques[2].is_satisfactory);

        // Improvement from first to last
        let improvement = critiques[2].quality_score - critiques[0].quality_score;
        assert_eq!(improvement, 0.38);
    }

    // ========== Complex Serialization Tests ==========

    #[test]
    fn test_critique_complex_serialization() {
        let critique = ReflectionCritique {
            quality_score: 0.777,
            strengths: vec![
                "Clear prose".to_string(),
                "Good examples with: special \"chars\"".to_string(),
            ],
            weaknesses: vec![
                "Missing: newline\ntest".to_string(),
            ],
            suggestions: vec![
                "Add\ttabs".to_string(),
                "Unicode: ğŸš€ æµ‹è¯•".to_string(),
            ],
            is_satisfactory: true,
        };

        let json_str = serde_json::to_string(&critique).unwrap();
        let deserialized: ReflectionCritique = serde_json::from_str(&json_str).unwrap();

        assert_eq!(critique.quality_score, deserialized.quality_score);
        assert_eq!(critique.strengths, deserialized.strengths);
        assert_eq!(critique.weaknesses, deserialized.weaknesses);
        assert_eq!(critique.suggestions, deserialized.suggestions);
        assert_eq!(critique.is_satisfactory, deserialized.is_satisfactory);
    }

    #[test]
    fn test_state_complex_serialization() {
        let state = ReflectionState {
            query: "Complex query with unicode: æµ‹è¯• ğŸ¯".to_string(),
            current_response: "Response\nwith\nmultiple\nlines".to_string(),
            response_history: vec![
                "First draft".to_string(),
                "Second draft".to_string(),
                "Third draft".to_string(),
            ],
            critique_history: vec![
                ReflectionCritique {
                    quality_score: 0.6,
                    strengths: vec![],
                    weaknesses: vec!["Weak".to_string()],
                    suggestions: vec!["Improve".to_string()],
                    is_satisfactory: false,
                },
                ReflectionCritique {
                    quality_score: 0.85,
                    strengths: vec!["Good".to_string()],
                    weaknesses: vec![],
                    suggestions: vec![],
                    is_satisfactory: true,
                },
            ],
            iteration_count: 2,
            final_response: Some("Final\nresponse".to_string()),
            quality_metrics: Some(QualityMetrics {
                final_score: 0.85,
                iterations: 2,
                improvement_delta: 0.25,
                threshold_met: true,
            }),
        };

        let json_str = serde_json::to_string(&state).unwrap();
        let deserialized: ReflectionState = serde_json::from_str(&json_str).unwrap();

        assert_eq!(state.query, deserialized.query);
        assert_eq!(state.current_response, deserialized.current_response);
        assert_eq!(state.response_history.len(), deserialized.response_history.len());
        assert_eq!(state.critique_history.len(), deserialized.critique_history.len());
        assert_eq!(state.iteration_count, deserialized.iteration_count);
        assert_eq!(state.final_response, deserialized.final_response);
        assert!(deserialized.quality_metrics.is_some());
    }

    #[test]
    fn test_quality_metrics_serialization() {
        let metrics = QualityMetrics {
            final_score: 0.923456,
            iterations: 7,
            improvement_delta: 0.423456,
            threshold_met: true,
        };

        let json_str = serde_json::to_string(&metrics).unwrap();
        let deserialized: QualityMetrics = serde_json::from_str(&json_str).unwrap();

        assert_eq!(metrics.final_score, deserialized.final_score);
        assert_eq!(metrics.iterations, deserialized.iterations);
        assert_eq!(metrics.improvement_delta, deserialized.improvement_delta);
        assert_eq!(metrics.threshold_met, deserialized.threshold_met);
    }
}