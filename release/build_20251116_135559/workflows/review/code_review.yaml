# Code Review Workflow
# Pattern: Multi-stage with Reflection
# Purpose: Comprehensive code review with quality assessment
#
# This workflow performs thorough code review in three stages:
# 1. Analyze changes (ReAct pattern) - Understand what changed
# 2. Quality review (Reflection pattern) - Deep quality assessment with self-critique
# 3. Generate report (ReAct pattern) - Produce structured review findings
#
# The Reflection pattern ensures thorough, high-quality review by having the
# agent critique its own analysis and iterate to catch missed issues.
#
# Use Cases:
# - Pre-commit code review
# - Pull request review
# - Security audit
# - Code quality assessment
# - Refactoring validation
# - Best practices compliance
#
# Tools Available:
# - git_diff: View code changes
# - file_read: Read full file context
# - grep: Search for patterns
# - shell_exec: Run linters, tests, security scanners
# - file_write: Generate review report

id: "code_review"
description: "Comprehensive code review with self-critique using Reflection pattern"

steps:
  # Step 1: Analyze what changed
  - name: "analyze_changes"
    pattern: "react_1"
    config:
      # Maximum iterations for analysis
      max_iterations: 5

      # Tools for analyzing changes
      tools:
        - git_diff
        - file_read
        - grep
        - fs_list

      # System prompt for change analysis
      system_prompt: |
        You are a code review assistant analyzing changes.

        Your task is to understand what changed:
        1. Use git diff to see the exact changes
        2. Read the full files to understand context
        3. Identify what functionality was modified
        4. Note files added, deleted, or renamed
        5. Understand the scope and intent of changes

        For each changed file, note:
        - What was changed (added, modified, deleted)
        - Why (based on code comments, patterns)
        - Impact (what other code might be affected)
        - Complexity (how significant is the change)

        Prepare a mental model of the changes for the quality review step.

    on_success: "quality_review"

  # Step 2: Deep quality review with reflection
  - name: "quality_review"
    pattern: "reflection_1"
    config:
      # Maximum reflection iterations
      max_iterations: 3

      # Quality threshold for review thoroughness
      quality_threshold: 0.80

      # Generator LLM configuration
      generator_config:
        model: "gpt-4"
        temperature: 0.3  # Deterministic for code review

      # Critic LLM configuration
      critic_config:
        model: "gpt-4"
        temperature: 0.2  # Very deterministic for critique

      # Tools for quality review
      tools:
        - file_read
        - shell_exec  # For running linters, tests
        - grep

      # System prompt for quality review
      system_prompt: |
        You are a senior code reviewer using the Reflection pattern.

        GENERATOR MODE (Code Review):
        Review the code changes for:

        1. CORRECTNESS
           - Does the code do what it's supposed to?
           - Are there logical errors or bugs?
           - Are edge cases handled?
           - Are there off-by-one errors, null checks, etc.?

        2. CODE STYLE
           - Follows project conventions?
           - Naming is clear and consistent?
           - Code is readable and well-formatted?
           - Comments are appropriate and helpful?

        3. PERFORMANCE
           - Are there obvious inefficiencies?
           - Unnecessary loops or allocations?
           - Could algorithms be improved?
           - Database queries optimized?

        4. SECURITY
           - Input validation present?
           - SQL injection risks?
           - XSS vulnerabilities?
           - Authentication/authorization correct?
           - Secrets properly handled?

        5. TESTING
           - Are tests included?
           - Test coverage adequate?
           - Tests actually test the right things?
           - Edge cases covered?

        6. MAINTAINABILITY
           - Code is understandable?
           - Complexity is manageable?
           - Dependencies are reasonable?
           - Technical debt introduced?

        7. ARCHITECTURE
           - Fits existing patterns?
           - Separation of concerns?
           - Proper abstraction levels?
           - No architectural violations?

        For each issue found:
        - Severity: Critical / Major / Minor / Nitpick
        - File: filename:line
        - Issue: description
        - Suggestion: how to fix

        CRITIC MODE (Self-Critique):
        Critique your own review:

        1. COMPLETENESS
           - Did you review ALL changes?
           - Did you check all review dimensions?
           - Did you miss any obvious issues?

        2. DEPTH
           - Did you actually read the code or skim?
           - Did you run tests/linters or just read?
           - Did you check context, not just diffs?

        3. ACCURACY
           - Are your findings actually issues?
           - Did you understand the code correctly?
           - Are severities appropriate?

        4. BALANCE
           - Too harsh or too lenient?
           - Focusing on style over substance?
           - Missing critical issues for nitpicks?

        Provide quality score (0.0-1.0):
        - 1.0 = Comprehensive, thorough review
        - 0.8-0.9 = Good review, minor gaps
        - Below 0.8 = Insufficient review depth

        REFINEMENT:
        Based on critique:
        - Re-examine flagged areas
        - Run additional checks (linters, tests)
        - Dig deeper into complex changes
        - Verify severity assessments

    on_success: "generate_report"

  # Step 3: Generate structured report
  - name: "generate_report"
    pattern: "react_1"
    config:
      # Maximum iterations for report generation
      max_iterations: 2

      # Tools for report writing
      tools:
        - file_write

      # System prompt for report generation
      system_prompt: |
        Generate a structured code review report.

        # Code Review Report

        ## Summary
        - Files changed: [count]
        - Lines added: [count]
        - Lines removed: [count]
        - Overall assessment: [Approve/Request Changes/Comment]

        ## Critical Issues
        (Must be fixed before merge)
        - [File:line] - [Issue description]
          - Severity: Critical
          - Problem: [what's wrong]
          - Fix: [how to address]

        ## Major Issues
        (Should be fixed before merge)
        - [File:line] - [Issue description]
          - Severity: Major
          - Problem: [what's wrong]
          - Fix: [how to address]

        ## Minor Issues
        (Nice to fix, not blocking)
        - [File:line] - [Issue description]
          - Severity: Minor
          - Suggestion: [improvement]

        ## Nitpicks
        (Style and preferences)
        - [File:line] - [Observation]

        ## Positive Feedback
        - [What was done well]
        - [Good patterns observed]

        ## Testing
        - Test coverage: [assessment]
        - Test quality: [assessment]
        - Recommendations: [if any]

        ## Security
        - Security review: [Pass/Concerns]
        - Issues found: [if any]
        - Recommendations: [if any]

        ## Performance
        - Performance impact: [assessment]
        - Concerns: [if any]

        ## Recommendation
        âœ… APPROVE - Ready to merge
        âš  REQUEST CHANGES - Issues must be addressed
        ðŸ’¬ COMMENT - Feedback provided, author's discretion

        ## Reviewer Notes
        - [Additional context]
        - [Suggested follow-up]

        Save this report as 'code_review_report.md'.

    on_success:
      end: true

# Global workflow settings
settings:
  # Maximum total steps across all stages
  max_total_steps: 15

  # Enable retries
  enable_retries: true

  # Maximum retries per step
  max_retries: 1

  # Timeout for entire review (5 minutes)
  timeout: 300
